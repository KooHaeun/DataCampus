{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Temporal Shift Module.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOAJpLiPz1Zmg5CzRXlOAwH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zwOCTqCOcZgk","executionInfo":{"status":"ok","timestamp":1628572011024,"user_tz":-540,"elapsed":18949,"user":{"displayName":"‍심윤주[ 학부재학 / 산업경영공학부 ]","photoUrl":"","userId":"01529369078242619291"}},"outputId":"f691ca15-968a-4432-f734-ce3ce9c352fa"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4WkVvS4ScmFE","executionInfo":{"status":"ok","timestamp":1628572137833,"user_tz":-540,"elapsed":247,"user":{"displayName":"‍심윤주[ 학부재학 / 산업경영공학부 ]","photoUrl":"","userId":"01529369078242619291"}},"outputId":"fdfbb92f-f22d-48b3-b8e6-2bae80076fb5"},"source":["cd \"/content/drive/Shareddrives/데이터 청년 캠퍼스\""],"execution_count":10,"outputs":[{"output_type":"stream","text":["/content/drive/Shareddrives/데이터 청년 캠퍼스\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hqh0Hn-Bb7KU","executionInfo":{"status":"ok","timestamp":1628572141866,"user_tz":-540,"elapsed":2484,"user":{"displayName":"‍심윤주[ 학부재학 / 산업경영공학부 ]","photoUrl":"","userId":"01529369078242619291"}},"outputId":"9fdf09cf-d48b-451c-b9bb-993b748b37a2"},"source":["!git clone https://github.com/mit-han-lab/temporal-shift-module.git"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Cloning into 'temporal-shift-module'...\n","remote: Enumerating objects: 226, done.\u001b[K\n","remote: Total 226 (delta 0), reused 0 (delta 0), pack-reused 226\u001b[K\n","Receiving objects: 100% (226/226), 237.44 KiB | 1004.00 KiB/s, done.\n","Resolving deltas: 100% (103/103), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jnhKDWPxeyT6","executionInfo":{"status":"ok","timestamp":1628572534232,"user_tz":-540,"elapsed":255,"user":{"displayName":"‍심윤주[ 학부재학 / 산업경영공학부 ]","photoUrl":"","userId":"01529369078242619291"}},"outputId":"e169cbe3-94f1-465b-f6f2-11cf383af38d"},"source":["cd \"/content/drive/Shareddrives/데이터 청년 캠퍼스/temporal-shift-module\""],"execution_count":15,"outputs":[{"output_type":"stream","text":["/content/drive/Shareddrives/데이터 청년 캠퍼스/temporal-shift-module\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xf0GZqaaOG-g"},"source":["temporal_shift.py"]},{"cell_type":"code","metadata":{"id":"RWEcqZooON2A"},"source":["#Naive implementation of TSM\n","\n","# shape of x: [N, T, C, H, W] \n","out = torch.zeros_like(x)\n","fold = c // fold_div\n","out[:, :-1, :fold] = x[:, 1:, :fold]  # shift left\n","out[:, 1:, fold: 2 * fold] = x[:, :-1, fold: 2 * fold]  # shift right\n","out[:, :, 2 * fold:] = x[:, :, 2 * fold:]  # not shift\n","return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgQ-McV0McPR","executionInfo":{"status":"ok","timestamp":1628570328249,"user_tz":-540,"elapsed":4576,"user":{"displayName":"‍심윤주[ 학부재학 / 산업경영공학부 ]","photoUrl":"","userId":"01529369078242619291"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class TemporalShift(nn.Module):\n","    def __init__(self, net, n_segment=3, n_div=8, inplace=False):\n","        super(TemporalShift, self).__init__()\n","        self.net = net\n","        self.n_segment = n_segment\n","        self.fold_div = n_div\n","        self.inplace = inplace\n","        if inplace:\n","            print('=> Using in-place shift...')\n","        print('=> Using fold div: {}'.format(self.fold_div))\n","\n","    def forward(self, x):\n","        x = self.shift(x, self.n_segment, fold_div=self.fold_div, inplace=self.inplace)\n","        return self.net(x)\n","\n","    @staticmethod\n","    def shift(x, n_segment, fold_div=3, inplace=False):\n","        nt, c, h, w = x.size()\n","        n_batch = nt // n_segment\n","        x = x.view(n_batch, n_segment, c, h, w)\n","\n","        fold = c // fold_div\n","        if inplace:\n","            # Due to some out of order error when performing parallel computing. \n","            # May need to write a CUDA kernel.\n","            raise NotImplementedError  \n","            # out = InplaceShift.apply(x, fold)\n","        else:\n","            out = torch.zeros_like(x)\n","            out[:, :-1, :fold] = x[:, 1:, :fold]  # shift left\n","            out[:, 1:, fold: 2 * fold] = x[:, :-1, fold: 2 * fold]  # shift right\n","            out[:, :, 2 * fold:] = x[:, :, 2 * fold:]  # not shift\n","\n","        return out.view(nt, c, h, w)\n","\n","\n","class InplaceShift(torch.autograd.Function):\n","    # Special thanks to @raoyongming for the help to this function\n","    @staticmethod\n","    def forward(ctx, input, fold):\n","        # not support higher order gradient\n","        # input = input.detach_()\n","        ctx.fold_ = fold\n","        n, t, c, h, w = input.size()\n","        buffer = input.data.new(n, t, fold, h, w).zero_()\n","        buffer[:, :-1] = input.data[:, 1:, :fold]\n","        input.data[:, :, :fold] = buffer\n","        buffer.zero_()\n","        buffer[:, 1:] = input.data[:, :-1, fold: 2 * fold]\n","        input.data[:, :, fold: 2 * fold] = buffer\n","        return input\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        # grad_output = grad_output.detach_()\n","        fold = ctx.fold_\n","        n, t, c, h, w = grad_output.size()\n","        buffer = grad_output.data.new(n, t, fold, h, w).zero_()\n","        buffer[:, 1:] = grad_output.data[:, :-1, :fold]\n","        grad_output.data[:, :, :fold] = buffer\n","        buffer.zero_()\n","        buffer[:, :-1] = grad_output.data[:, 1:, fold: 2 * fold]\n","        grad_output.data[:, :, fold: 2 * fold] = buffer\n","        return grad_output, None\n","\n","\n","class TemporalPool(nn.Module):\n","    def __init__(self, net, n_segment):\n","        super(TemporalPool, self).__init__()\n","        self.net = net\n","        self.n_segment = n_segment\n","\n","    def forward(self, x):\n","        x = self.temporal_pool(x, n_segment=self.n_segment)\n","        return self.net(x)\n","\n","    @staticmethod\n","    def temporal_pool(x, n_segment):\n","        nt, c, h, w = x.size()\n","        n_batch = nt // n_segment\n","        x = x.view(n_batch, n_segment, c, h, w).transpose(1, 2)  # n, c, t, h, w\n","        x = F.max_pool3d(x, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0))\n","        x = x.transpose(1, 2).contiguous().view(nt // 2, c, h, w)\n","        return x\n","\n","\n","def make_temporal_shift(net, n_segment, n_div=8, place='blockres', temporal_pool=False):\n","    if temporal_pool:\n","        n_segment_list = [n_segment, n_segment // 2, n_segment // 2, n_segment // 2]\n","    else:\n","        n_segment_list = [n_segment] * 4\n","    assert n_segment_list[-1] > 0\n","    print('=> n_segment per stage: {}'.format(n_segment_list))\n","\n","    import torchvision\n","    if isinstance(net, torchvision.models.ResNet):\n","        if place == 'block':\n","            def make_block_temporal(stage, this_segment):\n","                blocks = list(stage.children())\n","                print('=> Processing stage with {} blocks'.format(len(blocks)))\n","                for i, b in enumerate(blocks):\n","                    blocks[i] = TemporalShift(b, n_segment=this_segment, n_div=n_div)\n","                return nn.Sequential(*(blocks))\n","\n","            net.layer1 = make_block_temporal(net.layer1, n_segment_list[0])\n","            net.layer2 = make_block_temporal(net.layer2, n_segment_list[1])\n","            net.layer3 = make_block_temporal(net.layer3, n_segment_list[2])\n","            net.layer4 = make_block_temporal(net.layer4, n_segment_list[3])\n","\n","        elif 'blockres' in place:\n","            n_round = 1\n","            if len(list(net.layer3.children())) >= 23:\n","                n_round = 2\n","                print('=> Using n_round {} to insert temporal shift'.format(n_round))\n","\n","            def make_block_temporal(stage, this_segment):\n","                blocks = list(stage.children())\n","                print('=> Processing stage with {} blocks residual'.format(len(blocks)))\n","                for i, b in enumerate(blocks):\n","                    if i % n_round == 0:\n","                        blocks[i].conv1 = TemporalShift(b.conv1, n_segment=this_segment, n_div=n_div)\n","                return nn.Sequential(*blocks)\n","\n","            net.layer1 = make_block_temporal(net.layer1, n_segment_list[0])\n","            net.layer2 = make_block_temporal(net.layer2, n_segment_list[1])\n","            net.layer3 = make_block_temporal(net.layer3, n_segment_list[2])\n","            net.layer4 = make_block_temporal(net.layer4, n_segment_list[3])\n","    else:\n","        raise NotImplementedError(place)\n","\n","\n","def make_temporal_pool(net, n_segment):\n","    import torchvision\n","    if isinstance(net, torchvision.models.ResNet):\n","        print('=> Injecting nonlocal pooling')\n","        net.layer2 = TemporalPool(net.layer2, n_segment)\n","    else:\n","        raise NotImplementedError"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SOpOB_5AVmJY","executionInfo":{"status":"ok","timestamp":1628570580705,"user_tz":-540,"elapsed":13956,"user":{"displayName":"‍심윤주[ 학부재학 / 산업경영공학부 ]","photoUrl":"","userId":"01529369078242619291"}},"outputId":"6dacb65a-d043-42ef-eba3-b0fb5653f858"},"source":["if __name__ == '__main__':\n","    # test inplace shift v.s. vanilla shift\n","    tsm1 = TemporalShift(nn.Sequential(), n_segment=8, n_div=8, inplace=False)\n","    tsm2 = TemporalShift(nn.Sequential(), n_segment=8, n_div=8, inplace=False) #원래 코드 true 인데 error\n","\n","    print('=> Testing CPU...')\n","    # test forward\n","    with torch.no_grad():\n","        for i in range(10):\n","            x = torch.rand(2 * 8, 3, 224, 224)\n","            y1 = tsm1(x)\n","            y2 = tsm2(x)\n","            assert torch.norm(y1 - y2).item() < 1e-5\n","\n","    # test backward\n","    with torch.enable_grad():\n","        for i in range(10):\n","            x1 = torch.rand(2 * 8, 3, 224, 224)\n","            x1.requires_grad_()\n","            x2 = x1.clone()\n","            y1 = tsm1(x1)\n","            y2 = tsm2(x2)\n","            grad1 = torch.autograd.grad((y1 ** 2).mean(), [x1])[0]\n","            grad2 = torch.autograd.grad((y2 ** 2).mean(), [x2])[0]\n","            assert torch.norm(grad1 - grad2).item() < 1e-5\n","\n","    print('=> Testing GPU...')\n","    tsm1.cuda()\n","    tsm2.cuda()\n","    # test forward\n","    with torch.no_grad():\n","        for i in range(10):\n","            x = torch.rand(2 * 8, 3, 224, 224).cuda()\n","            y1 = tsm1(x)\n","            y2 = tsm2(x)\n","            assert torch.norm(y1 - y2).item() < 1e-5\n","\n","    # test backward\n","    with torch.enable_grad():\n","        for i in range(10):\n","            x1 = torch.rand(2 * 8, 3, 224, 224).cuda()\n","            x1.requires_grad_()\n","            x2 = x1.clone()\n","            y1 = tsm1(x1)\n","            y2 = tsm2(x2)\n","            grad1 = torch.autograd.grad((y1 ** 2).mean(), [x1])[0]\n","            grad2 = torch.autograd.grad((y2 ** 2).mean(), [x2])[0]\n","            assert torch.norm(grad1 - grad2).item() < 1e-5\n","    print('Test passed.')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["=> Using fold div: 8\n","=> Using fold div: 8\n","=> Testing CPU...\n","=> Testing GPU...\n","Test passed.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3eoMT3I9ZC_u","executionInfo":{"status":"ok","timestamp":1628572554630,"user_tz":-540,"elapsed":7331,"user":{"displayName":"‍심윤주[ 학부재학 / 산업경영공학부 ]","photoUrl":"","userId":"01529369078242619291"}},"outputId":"907d9d0a-ad34-44c7-92a4-8e8fdac84fbf"},"source":["# test TSN\n","!python test_models.py kinetics \\\n","    --weights=pretrained/TSM_kinetics_RGB_resnet50_avg_segment5_e50.pth \\\n","    --test_segments=8 --test_crops=1 \\\n","    --batch_size=64\n","\n","# test TSM\n","!python test_models.py kinetics \\\n","    --weights=pretrained/TSM_kinetics_RGB_resnet50_shift8_blockres_avg_segment8_e50.pth \\\n","    --test_segments=8 --test_crops=1 \\\n","    --batch_size=64"],"execution_count":16,"outputs":[{"output_type":"stream","text":["kinetics: 400 classes\n","=> shift: False, shift_div: None, shift_place: None\n","\n","    Initializing TSN with base model: resnet50.\n","    TSN Configurations:\n","        input_modality:     RGB\n","        num_segments:       1\n","        new_length:         1\n","        consensus_module:   avg\n","        dropout_ratio:      0.8\n","        img_feature_dim:    256\n","            \n","=> base model: resnet50\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100% 97.8M/97.8M [00:01<00:00, 60.5MB/s]\n","Traceback (most recent call last):\n","  File \"test_models.py\", line 141, in <module>\n","    checkpoint = torch.load(this_weights)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 594, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n","    super(_open_file, self).__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: 'pretrained/TSM_kinetics_RGB_resnet50_avg_segment5_e50.pth'\n","kinetics: 400 classes\n","=> shift: True, shift_div: 8, shift_place: blockres\n","\n","    Initializing TSN with base model: resnet50.\n","    TSN Configurations:\n","        input_modality:     RGB\n","        num_segments:       8\n","        new_length:         1\n","        consensus_module:   avg\n","        dropout_ratio:      0.8\n","        img_feature_dim:    256\n","            \n","=> base model: resnet50\n","Adding temporal shift...\n","=> n_segment per stage: [8, 8, 8, 8]\n","=> Processing stage with 3 blocks residual\n","=> Using fold div: 8\n","=> Using fold div: 8\n","=> Using fold div: 8\n","=> Processing stage with 4 blocks residual\n","=> Using fold div: 8\n","=> Using fold div: 8\n","=> Using fold div: 8\n","=> Using fold div: 8\n","=> Processing stage with 6 blocks residual\n","=> Using fold div: 8\n","=> Using fold div: 8\n","=> Using fold div: 8\n","=> Using fold div: 8\n","=> Using fold div: 8\n","=> Using fold div: 8\n","=> Processing stage with 3 blocks residual\n","=> Using fold div: 8\n","=> Using fold div: 8\n","=> Using fold div: 8\n","Traceback (most recent call last):\n","  File \"test_models.py\", line 141, in <module>\n","    checkpoint = torch.load(this_weights)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 594, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n","    super(_open_file, self).__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: 'pretrained/TSM_kinetics_RGB_resnet50_shift8_blockres_avg_segment8_e50.pth'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4xREmzJdONhh"},"source":[""]}]}